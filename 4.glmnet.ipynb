{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization and `glmnet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`glmnet` takes a matrix of predictors, so let’s construct one and leave out the `Salary` variable that we’re trying to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hitters<-Hitters[complete.cases(Hitters), ]\n",
    "X<-model.matrix(Salary~., data=Hitters)[, -1]\n",
    "median_salary<-median(Hitters$Salary)\n",
    "y_median<-as.numeric(Hitters$Salary >= median_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`glmnet` uses a regularization penalty of the “elasticnet” form\n",
    "\n",
    "$$ \\frac{1-\\alpha}{2} ||\\beta||_2 + \\alpha ||\\beta||_1 $$\n",
    "\n",
    "so $ \\alpha=1 $ corresponds to the lasso penalty and $ \\alpha=0\\ $ corresponds to ridge penalty. Let’s fit a lasso classification model for whether the salary is greater than the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.model.lasso<-glmnet(X, y_median, family=\"binomial\", alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show us the coefficients as a function of the norm (which is inverse to $ \\lambda $). Notice the number of non-zero coefficients along the top axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(c.model.lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let’s fit a lasso regression model for the salary itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.model.lasso<-glmnet(X, Hitters$Salary, family=\"gaussian\", alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(r.model.lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `cv.glmnet` function to do cross-validation and select the best value of $ \\lambda $ for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.cv.model.lasso<-cv.glmnet(X, y_median, family=\"binomial\", alpha=1, nfolds=10) # can also try type.measure=\"class\"\n",
    "r.cv.model.lasso<-cv.glmnet(X, Hitters$Salary, family=\"gaussian\", alpha=1, nfolds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the out-of-sample error as a function of $ \\lambda $ (notice the number of non-zero coefficients along the top axis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(c.cv.model.lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(r.cv.model.lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let’s see how to get the coefficients out. Let’s take the classification models as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attributes(c.model.lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.model.lasso$lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.model.lasso$beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the right, $ \\lambda $ is smallest, so more variables are included with larger coefficients. On the left, labmda is smaller, so fewer variables are included with smaller coefficients.\n",
    "\n",
    "Let’s take the 25th value of $ \\lambda $ as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.model.lasso$beta[, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let’s run a classification model with the ridge penalty. Notice that all features are always included, but their size shrinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.model.ridge<-glmnet(X, y_median, family=\"binomial\", alpha=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show us the coefficients as a function of the norm (which is inverse to $ \\lambda $):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(c.model.ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.cv.model.ridge<-cv.glmnet(X, y_median, family=\"binomial\", alpha=0, nfolds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(c.cv.model.ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
